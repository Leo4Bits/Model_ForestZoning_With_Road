{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f918ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.13.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "#!pip install -q torchmetrics # trên kaggle có lib này rồi, không cần install cũng dc\n",
    "!pip install -q segmentation-models-pytorch\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.utils.train import TrainEpoch as SMPTrainEpoch\n",
    "\n",
    "# --- DATASET ---\n",
    "class CloudDataset(BaseDataset):\n",
    "    def __init__(self, images_dir, masks_dir=None, augmentation=None, preprocessing=None, has_masks=True):\n",
    "        # Lọc chỉ lấy file _sat.jpg để tránh lấy nhầm file khác\n",
    "        self.ids = [os.path.splitext(f)[0].replace('_sat', '') for f in os.listdir(images_dir) if f.endswith('_sat.jpg')]\n",
    "        self.images_fps = [os.path.join(images_dir, image_id + '_sat.jpg') for image_id in self.ids]\n",
    "        self.has_masks = has_masks\n",
    "        \n",
    "        # Đường dẫn mask (Nếu dataset chuẩn DeepGlobe thì đuôi là _mask.png)\n",
    "        if self.has_masks:\n",
    "            self.masks_fps = [os.path.join(images_dir, image_id + '_mask.png') for image_id in self.ids]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Đọc ảnh\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "\n",
    "        mask_forest = None\n",
    "        if self.has_masks:\n",
    "            mask = cv2.imread(self.masks_fps[i])\n",
    "            if mask is None:\n",
    "                # Fallback nếu không đọc được mask\n",
    "                mask_forest = np.zeros((512, 512, 1), dtype=np.float32)\n",
    "            else:\n",
    "                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "                mask = cv2.resize(mask, (512, 512))\n",
    "                \n",
    "                # Mask màu xanh lá (Forest)\n",
    "                lower_green = np.array([0, 250, 0])\n",
    "                upper_green = np.array([5, 255, 5])\n",
    "                mask_forest = cv2.inRange(mask, lower_green, upper_green)\n",
    "                \n",
    "                # Chuẩn hóa về 0 và 1\n",
    "                mask_forest = (mask_forest / 255.0).astype('float32')\n",
    "                mask_forest = np.expand_dims(mask_forest, axis=-1)\n",
    "        else:\n",
    "            mask_forest = np.zeros((512, 512, 1), dtype=np.float32)\n",
    "\n",
    "        # Augmentation (nếu có)\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask_forest)\n",
    "            image, mask_forest = sample['image'], sample['mask']\n",
    "\n",
    "        # Preprocessing (Chuẩn hóa theo Imagenet)\n",
    "        if self.preprocessing:\n",
    "            image = self.preprocessing(image)\n",
    "\n",
    "        # Chuyển về Tensor (HWC -> CHW)\n",
    "        image = torch.from_numpy(image.transpose(2, 0, 1)).float()\n",
    "        mask_forest = torch.from_numpy(mask_forest.transpose(2, 0, 1)).float()\n",
    "\n",
    "        return image, mask_forest\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)\n",
    "\n",
    "# --- CONFIG ---\n",
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Tạo Model\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=1,\n",
    "    activation='sigmoid', # Output là xác suất (0-1)\n",
    ").to(DEVICE)\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# --- PATHS ---\n",
    "# Đảm bảo folder này tồn tại bên cột phải màn hình Kaggle\n",
    "x_train_dir = \"/kaggle/input/deepglobe-land-cover-classification-dataset/train\"\n",
    "\n",
    "# Check xem đường dẫn có đúng không trước khi chạy\n",
    "if not os.path.exists(x_train_dir):\n",
    "    print(f\"CẢNH BÁO: Đường dẫn {x_train_dir} không tồn tại!\")\n",
    "    print(\"Kiểm tra lại tên dataset đã Add vào \")\n",
    "else:\n",
    "    print(\"Đường dẫn hợp lệ.\")\n",
    "\n",
    "# Tạo Dataset & Loader\n",
    "train_dataset = CloudDataset(\n",
    "    x_train_dir, \n",
    "    preprocessing=preprocessing_fn,\n",
    "    has_masks=True\n",
    ")\n",
    "\n",
    "# GPU P100 RAM 16GB, Batch 10-16 là đẹp cho ResNet34\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "# --- LOSS & METRICS ---\n",
    "# Quan trọng: from_logits=False vì model đã có sigmoid\n",
    "loss = smp.losses.DiceLoss(mode='binary', from_logits=False) \n",
    "loss.__name__ = 'dice_loss'\n",
    "\n",
    "# Dùng Metric nội bộ của SMP để tránh lỗi tương thích\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "# Tạo Epoch Runner\n",
    "train_epoch = SMPTrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --- TRAINING LOOP ---\n",
    "print(f\"Bắt đầu train trên thiết bị: {DEVICE}\")\n",
    "\n",
    "# Save path\n",
    "save_path = '/kaggle/working/unet_forest_segmentation_model.pth'\n",
    "\n",
    "best_iou = 0.0\n",
    "\n",
    "for i in range(20):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    \n",
    "    # Logic lưu model: Chỉ lưu nếu IoU tăng (tùy chọn) hoặc lưu đè mỗi epoch\n",
    "    # Ở đây mình lưu đè mỗi epoch cho đơn giản\n",
    "    try:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
